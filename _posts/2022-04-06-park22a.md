---
title: Graph-Text Multi-Modal Pre-training for Medical Representation Learning
abstract: 'As the volume of Electronic Health Records (EHR) sharply grows, there has
  been emerging interest in learning the representation of EHR for healthcare applications.
  Representation learning of EHR requires appropriate modeling of the two dominant
  modalities in EHR: structured data and unstructured text. In this paper, we present
  MedGTX, a pre-trained model for multi-modal representation learning of the structured
  and textual EHR data. MedGTX uses a novel graph encoder to exploit the graphical
  nature of structured EHR data, and a text encoder to handle unstructured text, and
  a cross-modal encoder to learn a joint representation space. We pre-train our model
  through four proxy tasks on MIMIC-III, an open-source EHR data, and evaluate our
  model on two clinical benchmarks and three novel downstream tasks which tackle real-world
  problems in EHR data. The results consistently show the effectiveness of pre-training
  the model for joint representation of both structured and unstructured information
  from EHR. Given the promising performance of MedGTX, we believe this work opens
  a new door to jointly understanding the two fundamental modalities of EHR data.'
openreview: COrHjpxEbBC
software: https://github.com/sjpark9503/kg_txt_multimodal
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: park22a
month: 0
tex_title: Graph-Text Multi-Modal Pre-training for Medical Representation Learning
firstpage: 261
lastpage: 281
page: 261-281
order: 261
cycles: false
bibtex_author: Park, Sungjin and Bae, Seongsu and Kim, Jiho and Kim, Tackeun and Choi,
  Edward
author:
- given: Sungjin
  family: Park
- given: Seongsu
  family: Bae
- given: Jiho
  family: Kim
- given: Tackeun
  family: Kim
- given: Edward
  family: Choi
date: 2022-04-06
address:
container-title: Proceedings of the Conference on Health, Inference, and Learning
volume: '174'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 4
  - 6
pdf: https://proceedings.mlr.press/v174/park22a/park22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
